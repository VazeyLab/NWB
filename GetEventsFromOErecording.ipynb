{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install open-ephys-python-tools\n",
    "import open_ephys.analysis\n",
    "from open_ephys.analysis import Session\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO, NWBFile, TimeSeries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET THE DATA FROM ANAOLOG NIDAQ INPUT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=f\"D:\\\\Elia_Neuropixel\\\\2024-09-18_14-53-41\"\n",
    "\n",
    "session=Session(directory)\n",
    "recording = session.recordnodes[0].recordings[0]\n",
    "data = recording.continuous[1].get_samples(start_sample_index=0, end_sample_index=-1)\n",
    "\n",
    "# print(len(session.recordnodes)) #this will just be 1 unless multiple neuropixels are plugged in \n",
    "# print(session.__dir__())\n",
    "# session.directory\n",
    "# session.mmap_timestamps\n",
    "# session.recordnodes[0].recordings[0].continuous[1] #this is where nidaq is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PLOT TO FIND THE CUTOFF\n",
    "fig, ax = plt.subplots(2,4, figsize=(15,15))\n",
    "\n",
    "ax[0,0].plot((range(len(data[:,1]))),data[:,0])\n",
    "ax[0,1].plot((range(len(data[:,1]))),data[:,1])\n",
    "ax[0,2].plot((range(len(data[:,1]))),data[:,2])\n",
    "ax[0,3].plot((range(len(data[:,1]))),data[:,3])\n",
    "ax[1,0].plot((range(len(data[:,1]))),data[:,4])\n",
    "ax[1,1].plot((range(len(data[:,1]))),data[:,5])\n",
    "ax[1,2].plot((range(len(data[:,1]))),data[:,6])\n",
    "ax[1,3].plot((range(len(data[:,1]))),data[:,7])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#plt.plot(xlabel,data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(15,15))\n",
    "\n",
    "ax.plot((range(len(data[1268000:2268000,1]))),data[1268000:2268000,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTS_greaterthancutoff(signal, cutoff, sample):\n",
    "    TS_index = [ind for ind, ele in enumerate(signal) if ele >= cutoff] \n",
    "    onset=list()\n",
    "    onset.append(TS_index[0])\n",
    "\n",
    "    for i in range(len(TS_index)-1):\n",
    "        if TS_index[i+1]-TS_index[i]>1:\n",
    "            onset.append(TS_index[i+1])\n",
    "    \n",
    "    TSonset=[x/sample for x in onset]\n",
    "    return TSonset\n",
    "\n",
    "def findTS_lessthancutoff(signal, cutoff, sample):\n",
    "    TS_index = [ind for ind, ele in enumerate(signal) if ele <= cutoff] \n",
    "    offset=list()\n",
    "    onset=list()\n",
    "    onset.append(TS_index[0])\n",
    "\n",
    "    for i in range(len(TS_index)-1):\n",
    "        if TS_index[i+1]-TS_index[i]>1:\n",
    "            offset.append(TS_index[i])\n",
    "            onset.append(TS_index[i+1])\n",
    "    offset.append(TS_index[-1])\n",
    "    \n",
    "    TSoffset=[x/sample for x in offset]\n",
    "    TSonset=[x/sample for x in onset]\n",
    "\n",
    "    return TSonset, TSoffset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TS for lick - analog input 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIND TS FOR headfix lick - analog input 0\n",
    "\n",
    "#Set the variables for consistant across recordings - cutoff and sampling rate\n",
    "cutoff=3\n",
    "sample=30000\n",
    "\n",
    "#event 0\n",
    "signal=data[:,0]\n",
    "npx_lickon, npx_lickoff = findTS_lessthancutoff(signal,cutoff,sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deltalick=[x-y for x, y in zip(npx_lickoff, npx_lickon)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START AND STOP TIME OF EACH TRIAL - 1S PRE/POST LICK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get time intervals for each trial for NWB\n",
    "# this will be a little confusing until there are cues\n",
    "#NWB likes to have behavior data in 'trials' so teh start/end of trials \n",
    "# will be a little arbitrary right now - 1 second prior tp lick on and 1 sec after lick off \n",
    "\n",
    "\n",
    "npx_startTrial=[]\n",
    "for i in range(len(npx_lickon)):\n",
    "    npx_startTrial.append(float(npx_lickon[i]-1))\n",
    "npx_startTrial=np.array(npx_startTrial)\n",
    "# npx_startTrial+=npx_startTime\n",
    "\n",
    "\n",
    "npx_stopTrial=[]\n",
    "for i in range(len(npx_lickoff)):\n",
    "    npx_stopTrial.append(float(npx_lickoff[i]+1))\n",
    "npx_stopTrial=np.array(npx_stopTrial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD TRIALS IN NWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the file contains the new TimeSeries in acquisition\n",
    "filename = 'PRACTICE'\n",
    "\n",
    "with NWBHDF5IO(f\"F:\\\\EMR22010\\\\NWB\\\\{filename}.nwb\", \"r+\") as io:\n",
    "    read_nwbfile = io.read()\n",
    "\n",
    "    read_nwbfile.add_trial_column(name=\"lick_on\", description=\"Timestamp of lick onset\")\n",
    "    read_nwbfile.add_trial_column(name=\"lick_off\", description=\"Timestamp of lick offset\")\n",
    "\n",
    "    for i in range(len(npx_startTrial)):\n",
    "\n",
    "        read_nwbfile.add_trial(\n",
    "            start_time=float(npx_startTrial[i]),\n",
    "            stop_time=float(npx_stopTrial[i]),\n",
    "            lick_on=float(npx_lickon[i]),\n",
    "            lick_off=float(npx_lickoff[i])\n",
    "        )\n",
    "\n",
    "    io.write(read_nwbfile)\n",
    "    io.close()\n",
    "    #print(read_nwbfile.acquisition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET TRIALS FROM NWB - SANITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# io.close()\n",
    "# confirm the file contains the new TimeSeries in acquisition\n",
    "\n",
    "filename = 'PRACTICE'\n",
    "with NWBHDF5IO(f\"F:\\\\EMR22010\\\\NWB\\\\{filename}.nwb\", \"r+\") as io:\n",
    "    read_nwbfile = io.read()\n",
    "    trials=read_nwbfile.trials\n",
    "    trials_df=trials.to_dataframe()\n",
    "    print(trials)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trials_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NWB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
